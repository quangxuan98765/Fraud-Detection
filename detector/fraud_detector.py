from detector.database_manager import DatabaseManager
from detector.data_importer import DataImporter
from analysis.account_analyzer import AccountAnalyzer
from analysis.transaction_analyzer import TransactionAnalyzer
from analysis.pattern_detector import PatternDetector

class FraudDetector:
    def __init__(self):
        self.db_manager = DatabaseManager()
        self.data_importer = DataImporter(self.db_manager)
        self.account_analyzer = AccountAnalyzer(self.db_manager.driver)
        self.transaction_analyzer = TransactionAnalyzer(self.db_manager.driver)
        self.pattern_detector = PatternDetector(self.db_manager.driver)
        # Th√™m property driver ƒë·ªÉ ƒë·∫£m b·∫£o kh·∫£ nƒÉng t∆∞∆°ng th√≠ch v·ªõi c√°c API
        self.driver = self.db_manager.driver
        
    def check_data(self):
        """Ki·ªÉm tra xem ƒë√£ c√≥ d·ªØ li·ªáu trong database ch∆∞a"""
        return self.db_manager.check_data()
        
    def clear_database(self):
        """X√≥a to√†n b·ªô d·ªØ li·ªáu trong database"""
        return self.db_manager.clear_database()
            
    def import_data(self, csv_path):
        """Import d·ªØ li·ªáu s·ª≠ d·ª•ng API Neo4j thay v√¨ LOAD CSV"""
        return self.data_importer.import_data(csv_path)
    
    def finalize_and_evaluate(self):
        """Chu·∫©n h√≥a ƒëi·ªÉm v√† ƒë√°nh gi√° k·∫øt qu·∫£"""
        with self.db_manager.driver.session() as session:
            print("üîç ƒêang ho√†n t·∫•t ph√¢n t√≠ch...")
            
            # S·ª≠ d·ª•ng PatternDetector ƒë·ªÉ t√≠nh ƒëi·ªÉm cu·ªëi c√πng
            self.pattern_detector.calculate_fraud_scores()
            
            # ƒê√°nh d·∫•u t√†i kho·∫£n c√≥ r·ªßi ro cao d·ª±a tr√™n nhi·ªÅu ti√™u ch√≠
            print("  ƒêang ƒë√°nh d·∫•u t√†i kho·∫£n c√≥ r·ªßi ro cao...")
            session.run("""
                MATCH (a:Account)
                WHERE 
                    (a.fraud_score > 0.7) OR
                    (a.tx_anomaly = true AND a.tx_imbalance > 0.7) OR
                    (a.cycle_boost > 0.3 AND a.pagerank_score > 0.6) OR
                    (a.similarity_score > 0.7 AND a.base_score > 0.6) OR 
                    (a.pagerank_score > 0.6 AND a.tx_imbalance > 0.7 AND a.cycle_boost > 0.2)                SET a.high_risk = true,
                     a.risk_factors = CASE WHEN a.fraud_score > 0.7 THEN ['high_fraud_score']
                         + CASE WHEN a.tx_anomaly = true AND a.tx_imbalance > 0.7 THEN ['transaction_anomaly'] ELSE [] END
                         + CASE WHEN a.cycle_boost > 0.3 AND a.pagerank_score > 0.6 THEN ['suspicious_cycle'] ELSE [] END
                         + CASE WHEN a.similarity_score > 0.7 AND a.base_score > 0.6 THEN ['similar_to_suspicious'] ELSE [] END
                         + CASE WHEN a.pagerank_score > 0.6 AND a.tx_imbalance > 0.7 AND a.cycle_boost > 0.2 THEN ['combined_factors'] ELSE [] END
                     ELSE
                         CASE WHEN a.tx_anomaly = true AND a.tx_imbalance > 0.7 THEN ['transaction_anomaly'] ELSE [] END
                         + CASE WHEN a.cycle_boost > 0.3 AND a.pagerank_score > 0.6 THEN ['suspicious_cycle'] ELSE [] END
                         + CASE WHEN a.similarity_score > 0.7 AND a.base_score > 0.6 THEN ['similar_to_suspicious'] ELSE [] END
                         + CASE WHEN a.pagerank_score > 0.6 AND a.tx_imbalance > 0.7 AND a.cycle_boost > 0.2 THEN ['combined_factors'] ELSE [] END
                     END
            """)
            
            # Validate detection effectiveness
            print("  ƒêang ki·ªÉm tra hi·ªáu qu·∫£ ph√°t hi·ªán...")
            validation = session.run("""
                MATCH (a:Account)
                WHERE a.high_risk = true
                
                WITH collect(DISTINCT a.risk_factors) AS all_factors,
                     count(DISTINCT a) AS flagged_accounts,
                     count(DISTINCT CASE WHEN size(a.risk_factors) > 1 THEN a END) AS multi_factor,
                     count(DISTINCT CASE WHEN 'high_fraud_score' IN a.risk_factors THEN a END) AS fraud_score,
                     count(DISTINCT CASE WHEN 'transaction_anomaly' IN a.risk_factors THEN a END) AS tx_anomaly,
                     count(DISTINCT CASE WHEN 'suspicious_cycle' IN a.risk_factors THEN a END) AS cycles,
                     count(DISTINCT CASE WHEN 'similar_to_suspicious' IN a.risk_factors THEN a END) AS similar,
                     count(DISTINCT CASE WHEN 'combined_factors' IN a.risk_factors THEN a END) AS combined
                RETURN 
                    flagged_accounts,
                    multi_factor,
                    1.0 * multi_factor / flagged_accounts AS multi_factor_ratio,
                    fraud_score, tx_anomaly, cycles, similar, combined
            """).single()
            
            if validation:
                flagged = validation.get("flagged_accounts", 0)
                multi = validation.get("multi_factor", 0)
                multi_ratio = validation.get("multi_factor_ratio", 0)
                fraud_score = validation.get("fraud_score", 0)
                tx_anomaly = validation.get("tx_anomaly", 0)
                cycles = validation.get("cycles", 0)
                similar = validation.get("similar", 0)
                combined = validation.get("combined", 0)
                
                print(f"\nK·∫øt qu·∫£ ph√°t hi·ªán gian l·∫≠n:")
                print(f"  T·ªïng s·ªë t√†i kho·∫£n ƒë√°ng ng·ªù: {flagged}")
                print(f"  - C√≥ nhi·ªÅu y·∫øu t·ªë: {multi} ({multi_ratio:.1%})")
                print(f"  - ƒêi·ªÉm gian l·∫≠n cao: {fraud_score}")
                print(f"  - Giao d·ªãch b·∫•t th∆∞·ªùng: {tx_anomaly}")
                print(f"  - N·∫±m trong chu tr√¨nh: {cycles}")
                print(f"  - T∆∞∆°ng t·ª± t√†i kho·∫£n kh√°c: {similar}")
                print(f"  - K·∫øt h·ª£p nhi·ªÅu y·∫øu t·ªë: {combined}")
            
            return True

    def process_high_risk_communities(self):
        """X·ª≠ l√Ω c√°c c·ªông ƒë·ªìng c√≥ nguy c∆° cao"""
        # S·ª≠ d·ª•ng PatternDetector c√≥ c√°c ph∆∞∆°ng th·ª©c t∆∞∆°ng t·ª±
        # Ph∆∞∆°ng th·ª©c n√†y ƒë∆∞·ª£c bao g·ªìm trong analyze_fraud
        return True

    def analyze_fraud(self):
        """Ch·∫°y ph√¢n t√≠ch gian l·∫≠n v·ªõi c√°c thu·∫≠t to√°n ƒë·ªì th·ªã"""
        try:
            with self.db_manager.driver.session() as session:
                # X√≥a d·ªØ li·ªáu ph√¢n t√≠ch c≈©
                print("üîç ƒêang x√≥a ph√¢n t√≠ch c≈©...")
                session.run("""
                    MATCH (a:Account) 
                    REMOVE a.fraud_score, a.community, a.pagerank_score, 
                        a.degree_score, a.similarity_score, a.path_score, a.known_fraud,
                        a.base_score, a.tx_anomaly, a.high_tx_volume, a.only_sender
                """)
    
                # X√≥a m·ªëi quan h·ªá SIMILAR_TO
                print("üîç ƒêang x√≥a m·ªëi quan h·ªá t·ª´ ph√¢n t√≠ch tr∆∞·ªõc...")
                session.run("""
                    MATCH ()-[r:SIMILAR_TO]->()
                    DELETE r
                """)
                
                # T·∫°o index
                session.run("CREATE INDEX IF NOT EXISTS FOR (a:Account) ON (a.id)")
                
                # X√≥a projected graph c≈©
                print("üîç ƒêang x√≥a projected graph c≈©...")
                try:
                    result = session.run("""
                        CALL gds.graph.list()
                        YIELD graphName
                        WHERE graphName = 'fraud_graph'
                        RETURN count(*) > 0 AS exists
                    """).single()
    
                    if result and result.get('exists', False):
                        print("  ƒê√£ t√¨m th·∫•y projected graph trong danh s√°ch, ƒëang x√≥a...")
                        session.run("CALL gds.graph.drop('fraud_graph', false)")
                except Exception as e:
                    print(f"  L·ªói khi ki·ªÉm tra projected graph: {e}")                # 1. T·∫°o projected graph ban ƒë·∫ßu (ch·ªâ d√πng amount, kh√¥ng d√πng is_fraud)
                print("üîç ƒêang t·∫°o projected graph...")
                session.run("""
                    CALL gds.graph.project(
                        'fraud_graph',
                        'Account',
                        'SENT',
                        {
                            relationshipProperties: {
                                amount: {property: 'amount', defaultValue: 0.0}
                            }
                        }
                    )
                """)
                
                # 2. Degree Centrality
                print("üîç ƒêang t√≠nh Degree Centrality...")
                session.run("""
                    CALL gds.degree.write('fraud_graph', {
                        writeProperty: 'degree_score'
                    })
                """)
                
                # 3. PageRank
                print("üîç ƒêang ch·∫°y PageRank...")
                session.run("""
                    CALL gds.pageRank.write('fraud_graph', {
                        writeProperty: 'pagerank_score',
                        maxIterations: 20
                    })
                """)
                
                # 4. Louvain - Ph√°t hi·ªán c·ªông ƒë·ªìng (kh√¥ng d√πng seedProperty v√¨ g√¢y l·ªói)
                print("üîç ƒêang ph√°t hi·ªán c·ªông ƒë·ªìng v·ªõi Louvain...")
                session.run("""
                    CALL gds.louvain.write('fraud_graph', {
                        writeProperty: 'community',
                        maxLevels: 10,           // Gi·ªõi h·∫°n s·ªë level c·ªßa thu·∫≠t to√°n
                        maxIterations: 20,       // S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa
                        tolerance: 0.0001,       // Gi√° tr·ªã ng∆∞·ª°ng ƒë·ªÉ h·ªôi t·ª• cao h∆°n
                        includeIntermediateCommunities: false  // Kh√¥ng l∆∞u c√°c c·ªông ƒë·ªìng trung gian
                    })
                """)
                
                # Th·ªëng k√™ c√°c c·ªông ƒë·ªìng ph√°t hi·ªán ƒë∆∞·ª£c
                community_stats = session.run("""
                    MATCH (a:Account)
                    WHERE a.community IS NOT NULL
                    WITH a.community AS community, count(*) AS size
                    RETURN 
                        count(*) AS total_communities,
                        sum(CASE WHEN size = 1 THEN 1 ELSE 0 END) AS single_node_communities,
                        sum(CASE WHEN size >= 2 AND size <= 5 THEN 1 ELSE 0 END) AS small_communities,
                        sum(CASE WHEN size > 5 AND size <= 20 THEN 1 ELSE 0 END) AS medium_communities,
                        sum(CASE WHEN size > 20 THEN 1 ELSE 0 END) AS large_communities,
                        avg(size) AS avg_community_size,
                        max(size) AS max_community_size
                """).single()
                
                if community_stats:
                    print(f"  T·ªïng s·ªë c·ªông ƒë·ªìng: {community_stats['total_communities']}")
                    print(f"  C·ªông ƒë·ªìng m·ªôt n√∫t: {community_stats['single_node_communities']} " + 
                          f"({community_stats['single_node_communities']/community_stats['total_communities']*100:.1f}%)")
                    print(f"  C·ªông ƒë·ªìng nh·ªè (2-5 n√∫t): {community_stats['small_communities']}")
                    print(f"  C·ªông ƒë·ªìng trung b√¨nh (6-20 n√∫t): {community_stats['medium_communities']}")
                    print(f"  C·ªông ƒë·ªìng l·ªõn (>20 n√∫t): {community_stats['large_communities']}")
                    print(f"  K√≠ch th∆∞·ªõc trung b√¨nh: {community_stats['avg_community_size']:.2f}")
                    print(f"  K√≠ch th∆∞·ªõc l·ªõn nh·∫•t: {community_stats['max_community_size']}")
                    
                    # N·∫øu c√≥ qu√° nhi·ªÅu c·ªông ƒë·ªìng ƒë∆°n l·∫ª, th·ª±c hi·ªán gom nh√≥m l·∫°i
                    single_percent = community_stats['single_node_communities']/community_stats['total_communities']
                    if single_percent > 0.8:  # N·∫øu h∆°n 80% l√† c·ªông ƒë·ªìng m·ªôt n√∫t
                        print("  ƒêang gom nh√≥m c√°c c·ªông ƒë·ªìng nh·ªè...")
                        # G√°n c·ªông ƒë·ªìng m·ªõi d·ª±a tr√™n pagerank_score (chia th√†nh 5 nh√≥m)
                        session.run("""
                            MATCH (a:Account)
                            WHERE a.community IS NOT NULL AND (a)-[:SENT]->() OR ()-[:SENT]->(a)
                            WITH a, a.pagerank_score AS score
                            ORDER BY score DESC
                            WITH collect(a) AS all_accounts, count(*) AS total
                            WITH all_accounts, total, 
                                 total / 5 AS group_size
                            UNWIND range(0, 4) as group_id
                            WITH all_accounts, group_id, group_size
                            WITH all_accounts[group_id * group_size..(group_id + 1) * group_size] AS accounts, group_id
                            UNWIND accounts AS account
                            SET account.consolidated_community = group_id
                            RETURN count(*) as grouped
                        """)
                        # X·ª≠ l√Ω c√°c n√∫t kh√¥ng c√≥ giao d·ªãch n√†o
                        session.run("""
                            MATCH (a:Account)
                            WHERE NOT EXISTS(a.consolidated_community)
                            SET a.consolidated_community = 5
                        """)
                        # S·ª≠ d·ª•ng consolidated_community thay v√¨ community
                        session.run("""
                            MATCH (a:Account)
                            SET a.community = a.consolidated_community
                            REMOVE a.consolidated_community
                        """)
                        
                # 5. Node Similarity
                print("üîç ƒêang t√≠nh Node Similarity...")
                session.run("""
                    CALL gds.nodeSimilarity.write('fraud_graph', {
                        writeProperty: 'similarity_score',
                        writeRelationshipType: 'SIMILAR_TO',
                        topK: 10
                    })
                """)
                
                # 6. Ph√¢n t√≠ch giao d·ªãch
                print("üîç ƒêang t√≠nh giao d·ªãch ra/v√†o...")
                self.transaction_analyzer.process_transaction_stats()
    
                # 7. Ph√¢n t√≠ch h√†nh vi t√†i kho·∫£n
                print("üîç ƒêang ƒë√°nh d·∫•u h√†nh vi b·∫•t th∆∞·ªùng...")
                self.account_analyzer.process_account_behaviors()
                self.account_analyzer.process_transaction_anomalies()
                
                # 8. T√≠nh ƒëi·ªÉm gian l·∫≠n
                print("üîç ƒêang t√≠nh ƒëi·ªÉm gian l·∫≠n t·ªïng h·ª£p...")
                self.pattern_detector.calculate_fraud_scores()
                
                # 9. Ho√†n t·∫•t ph√¢n t√≠ch
                print("üîç ƒêang ho√†n t·∫•t ph√¢n t√≠ch...")
                self.finalize_and_evaluate()
                
                # 10. X√≥a projected graph ƒë·ªÉ gi·∫£i ph√≥ng b·ªô nh·ªõ
                print("üîç ƒêang x√≥a projected graph...")
                self.db_manager.cleanup_projected_graph()
                print("‚úÖ Ph√¢n t√≠ch gian l·∫≠n ho√†n t·∫•t.")
                return True
                
        except Exception as e:
            print(f"L·ªói khi ph√¢n t√≠ch gian l·∫≠n: {e}")
            return False
            
    def cleanup_projected_graph(self):
        """X√≥a projected graph v·ªõi c∆° ch·∫ø timeout v√† b·ªè qua vi·ªác ki·ªÉm tra t·ªìn t·∫°i"""
        return self.db_manager.cleanup_projected_graph()
    
    def close(self):
        """ƒê√≥ng k·∫øt n·ªëi ƒë·∫øn Neo4j"""
        self.db_manager.close()
