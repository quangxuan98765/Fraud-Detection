from neo4j import GraphDatabase
import pandas as pd
import logging
import time
from .utils.config import BATCH_SIZE, MAX_NODES, MAX_RELATIONSHIPS
from .queries.database_manager_queries import (
    # Import queries
    CREATE_ACCOUNT_INDEX,
    CREATE_ACCOUNTS_QUERY,
    CREATE_TRANSACTIONS_QUERY,
    
    # Check queries
    COUNT_ALL_NODES,
    COUNT_ACCOUNTS,
    COUNT_TRANSACTIONS,
    CHECK_ANALYZED,
    
    # Cleanup queries
    DROP_ACCOUNT_INDEX,
    DELETE_ALL,
    
    # Graph projection queries
    get_main_projection,
    get_similarity_projection,
    get_temporal_projection,
    get_drop_graph_query,
    
    # Property cleanup queries
    get_cleanup_node_properties_query,
    CLEANUP_RELATIONSHIP_PROPERTIES,
    DELETE_SIMILAR_RELATIONSHIPS
)

# Disable Neo4j driver's INFO and WARNING logs
logging.getLogger("neo4j").setLevel(logging.ERROR)

class DatabaseManager:
    def __init__(self, uri, user, password):
        """Kh·ªüi t·∫°o k·∫øt n·ªëi Neo4j."""
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
    
    def close(self):
        """ƒê√≥ng k·∫øt n·ªëi Neo4j."""
        if self.driver:
            self.driver.close()
    
    def run_query(self, query, params=None):
        """Ch·∫°y truy v·∫•n Cypher v√† tr·∫£ v·ªÅ k·∫øt qu·∫£."""
        with self.driver.session() as session:
            try:
                if params:
                    result = session.run(query, params)
                else:
                    result = session.run(query)
                    
                # Check if the result has records without consuming them
                has_records = result.peek() is not None
                
                if not has_records:
                    # For queries that don't return data (CREATE, SET, DELETE, ...)
                    return None
                else:
                    # For queries that return data, collect them first to avoid consumption issues
                    data = result.data()
                    if len(data) == 0:
                        return None
                        
                    # If we expect to use single() later
                    # Return the first record directly
                    return data[0]
            except Exception as e:
                print(f"Query error: {str(e)}")
                raise e
                    
    def import_data(self, csv_path):
        """Import d·ªØ li·ªáu s·ª≠ d·ª•ng API Neo4j thay v√¨ LOAD CSV"""
        try:            # ƒê·ªçc file CSV
            df = pd.read_csv(csv_path)
            print(f"ƒê√£ ƒë·ªçc file CSV: {len(df)} giao d·ªãch")
            
            # Ki·ªÉm tra c√°c c·ªôt b·∫Øt bu·ªôc
            required_columns = ['nameOrig', 'nameDest', 'amount', 'step', 'type']
            for col in required_columns:
                if col not in df.columns:
                    raise ValueError(f"Thi·∫øu c·ªôt {col} trong file CSV")
              # Ki·ªÉm tra v√† x·ª≠ l√Ω c·ªôt is_fraud ho·∫∑c isFraud
            if 'is_fraud' not in df.columns:
                if 'isFraud' in df.columns:
                    print("T√¨m th·∫•y c·ªôt isFraud, mapping sang is_fraud")
                    df['is_fraud'] = df['isFraud']
                else:
                    print("Kh√¥ng t√¨m th·∫•y c·ªôt is_fraud ho·∫∑c isFraud trong d·ªØ li·ªáu, t·∫°o c·ªôt m·∫∑c ƒë·ªãnh v·ªõi gi√° tr·ªã 0")
                    df['is_fraud'] = 0
            
            with self.driver.session() as session:
                # T·∫°o index v√† x√≥a d·ªØ li·ªáu c≈©
                session.run(CREATE_ACCOUNT_INDEX)
                
                # L·∫•y danh s√°ch t√†i kho·∫£n ƒë·ªôc nh·∫•t
                all_accounts = set(df['nameOrig'].unique()) | set(df['nameDest'].unique())
                print(f"T·ªïng s·ªë t√†i kho·∫£n: {len(all_accounts)}")
                
                # Gi·ªõi h·∫°n s·ªë t√†i kho·∫£n n·∫øu c·∫ßn
                if len(all_accounts) > MAX_NODES:
                    print(f"Gi·ªõi h·∫°n s·ªë t√†i kho·∫£n t·ªëi ƒëa: {MAX_NODES}")
                    all_accounts = list(all_accounts)[:MAX_NODES]
                
                # 1. T·∫°o t√†i kho·∫£n (nodes)
                print("ƒêang t·∫°o t√†i kho·∫£n...")
                start_time = time.time()
                
                account_batches = [list(all_accounts)[i:i+BATCH_SIZE] for i in range(0, len(all_accounts), BATCH_SIZE)]
                for i, account_batch in enumerate(account_batches):
                    session.run(CREATE_ACCOUNTS_QUERY, {"accounts": account_batch})
                    print(f"  ƒê√£ t·∫°o {(i+1)*BATCH_SIZE if (i+1)*BATCH_SIZE < len(all_accounts) else len(all_accounts)}/{len(all_accounts)} t√†i kho·∫£n")
                
                # 2. T·∫°o giao d·ªãch (relationships) - gi·ªõi h·∫°n s·ªë l∆∞·ª£ng n·∫øu c·∫ßn
                if len(df) > MAX_RELATIONSHIPS:
                    print(f"Gi·ªõi h·∫°n s·ªë giao d·ªãch t·ªëi ƒëa: {MAX_RELATIONSHIPS}")
                    df = df.head(MAX_RELATIONSHIPS)
                
                print("ƒêang t·∫°o giao d·ªãch...")
                tx_batches = [df.iloc[i:i+BATCH_SIZE] for i in range(0, len(df), BATCH_SIZE)]
                
                for i, batch_df in enumerate(tx_batches):
                    records = []
                    for _, row in batch_df.iterrows():
                        # Ch·ªâ th√™m giao d·ªãch n·∫øu c·∫£ hai t√†i kho·∫£n ƒë·ªÅu trong danh s√°ch t√†i kho·∫£n ƒë√£ l·ªçc
                        if row['nameOrig'] in all_accounts and row['nameDest'] in all_accounts:
                            records.append({
                                "from_ac": row['nameOrig'],
                                "to_ac": row['nameDest'],
                                "amount": float(row['amount']),
                                "step": int(row['step']),
                                "is_fraud": int(row['is_fraud']),
                                "type": row['type']
                            })
                    
                    session.run(CREATE_TRANSACTIONS_QUERY, {"batch": records})
                    
                    progress = (i+1)/len(tx_batches)*100
                    print(f"  ƒê√£ t·∫°o {progress:.1f}% giao d·ªãch ({(i+1)*BATCH_SIZE if (i+1)*BATCH_SIZE < len(df) else len(df)}/{len(df)})")
                
                print(f"Ho√†n th√†nh import trong {time.time() - start_time:.2f}s")
                return True
                
        except Exception as e:
            print(f"L·ªói khi import d·ªØ li·ªáu: {e}")
            return False

    def check_data(self):
        """Ki·ªÉm tra xem ƒë√£ c√≥ d·ªØ li·ªáu trong database ch∆∞a"""
        with self.driver.session() as session:
            result = session.run(COUNT_ALL_NODES)
            count = result.single()["count"]
            
            # L·∫•y th√™m th·ªëng k√™
            stats = {}
            try:
                accounts = session.run(COUNT_ACCOUNTS).single()
                stats["accounts"] = accounts["count"] if accounts else 0
                
                transactions = session.run(COUNT_TRANSACTIONS).single()
                stats["transactions"] = transactions["count"] if transactions else 0
                
                has_analysis = session.run(CHECK_ANALYZED).single()
                stats["has_analysis"] = has_analysis["count"] > 0 if has_analysis else False
            except:
                stats = {"accounts": 0, "transactions": 0, "has_analysis": False}
                
            return count > 0, stats
        
    def clear_database(self):
        """X√≥a to√†n b·ªô d·ªØ li·ªáu trong database"""
        with self.driver.session() as session:
            try:
                # X√≥a c√°c indexes tr∆∞·ªõc (n·∫øu c√≥)
                try:
                    session.run(DROP_ACCOUNT_INDEX)
                except:
                    pass
                    
                # X√≥a t·∫•t c·∫£ nodes v√† relationships
                session.run(DELETE_ALL)
                
                # Ki·ªÉm tra l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√£ x√≥a th√†nh c√¥ng
                result = session.run(COUNT_ALL_NODES).single()
                is_empty = result["count"] == 0
                
                if is_empty:
                    print("ƒê√£ x√≥a th√†nh c√¥ng to√†n b·ªô d·ªØ li·ªáu t·ª´ database")
                else:
                    print(f"V·∫´n c√≤n {result['count']} nodes trong database")
                    
                return is_empty
            except Exception as e:
                print(f"L·ªói khi x√≥a database: {e}")
                return False
            
    def create_graph_projections(self):
        """T·∫°o c√°c graph projection d√πng cho c√°c thu·∫≠t to√°n GDS."""
        print("üîÑ ƒêang t·∫°o c√°c graph projection...")
        
        # T·∫°o timestamp ƒë·ªÉ ƒë·∫£m b·∫£o t√™n graph l√† duy nh·∫•t
        timestamp = int(time.time())
        self.main_graph_name = f'main-graph-{timestamp}'
        self.similarity_graph_name = f'account-similarity-{timestamp}'
        self.temporal_graph_name = f'temporal-graph-{timestamp}'
        
        # 1. Graph projection cho c√°c Account v√† m·ªëi quan h·ªá SENT
        self.run_query(get_main_projection(self.main_graph_name))
        
        # 2. Graph projection cho account similarity
        self.run_query(get_similarity_projection(self.similarity_graph_name))
        
        # 3. Graph projection cho temporal analysis
        self.run_query(get_temporal_projection(self.temporal_graph_name))
        
        print("‚úÖ ƒê√£ t·∫°o xong c√°c graph projection.")
            
    def delete_graph_projections(self):
        """X√≥a c√°c graph projections ƒë√£ t·∫°o."""
        print("üîÑ ƒêang x√≥a c√°c graph projections...")
        
        # X√≥a c√°c graph projections c·ª• th·ªÉ
        try:
            self.run_query(get_drop_graph_query(self.main_graph_name))
            self.run_query(get_drop_graph_query(self.similarity_graph_name))
            self.run_query(get_drop_graph_query(self.temporal_graph_name))
            self.run_query(get_drop_graph_query(f"{self.main_graph_name}-undirected"))
            self.run_query(get_drop_graph_query(f"{self.main_graph_name}-undirected-tri"))
            print("‚úÖ ƒê√£ x√≥a t·∫•t c·∫£ c√°c graph projections.")
        except Exception as e:
            print(f"‚ö†Ô∏è L∆∞u √Ω khi x√≥a graph: {str(e)}")
                
    def cleanup_properties(self):
        """X√≥a t·∫•t c·∫£ c√°c thu·ªôc t√≠nh ƒë∆∞·ª£c th√™m v√†o trong qu√° tr√¨nh ph√¢n t√≠ch ƒë·ªÉ tr√°nh ƒë·∫ßy database."""
        print("üîÑ ƒêang d·ªçn d·∫πp c√°c thu·ªôc t√≠nh ph√¢n t√≠ch...")
        
        # Danh s√°ch c√°c thu·ªôc t√≠nh ƒë∆∞·ª£c th√™m v√†o trong qu√° tr√¨nh ph√¢n t√≠ch
        added_properties = [
            'degScore', 'prScore', 'communityId', 'communitySize', 'normCommunitySize',
            'simScore', 'btwScore', 'hubScore', 'authScore', 'coreScore', 'triCount',
            'cycleCount', 'tempBurst', 'tempBurst1h', 'tempBurst24h', 'anomaly_score', 'flagged'
        ]
        
        try:
            # X√≥a thu·ªôc t√≠nh tr√™n t·∫•t c·∫£ c√°c node
            self.run_query(get_cleanup_node_properties_query(added_properties))
            
            # X√≥a thu·ªôc t√≠nh tr√™n c√°c relationship
            self.run_query(CLEANUP_RELATIONSHIP_PROPERTIES)
            print(f"‚úÖ ƒê√£ x√≥a {len(added_properties)} thu·ªôc t√≠nh ph√¢n t√≠ch kh·ªèi database.")
            
            # X√≥a c√°c m·ªëi quan h·ªá SIMILAR (t·ª´ Node Similarity)
            self.run_query(DELETE_SIMILAR_RELATIONSHIPS)
            print("‚úÖ ƒê√£ x√≥a c√°c m·ªëi quan h·ªá SIMILAR.")
            
            return True
        except Exception as e:
            print(f"‚ùå L·ªói khi d·ªçn d·∫πp thu·ªôc t√≠nh: {str(e)}")
            return False