#!/usr/bin/env python3
"""
C√¥ng c·ª• c·∫≠p nh·∫≠t c·∫•u h√¨nh tr·ªçng s·ªë cho h·ªá th·ªëng ph√°t hi·ªán gian l·∫≠n
D·ª±a tr√™n ph√¢n t√≠ch t∆∞∆°ng quan v√† th·ª≠ nghi·ªám th·ª±c t·∫ø
"""
import json
import os
import argparse
import sys

# Th√™m th∆∞ m·ª•c g·ªëc v√†o sys.path ƒë·ªÉ c√≥ th·ªÉ import c√°c module
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def update_config_file(config_path, new_weights, new_percentile):
    """C·∫≠p nh·∫≠t file c·∫•u h√¨nh Python."""
    if not os.path.exists(config_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file c·∫•u h√¨nh t·∫°i {config_path}")
        return False
    
    with open(config_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # T·∫°o chu·ªói tr·ªçng s·ªë m·ªõi
    weights_str = "# Feature weights\nFEATURE_WEIGHTS = {\n"
    for feature, weight in new_weights.items():
        weights_str += f"    '{feature}': {weight:.2f},\n"
    weights_str += "}\n"
    
    # T√¨m v√† thay th·∫ø ph·∫ßn tr·ªçng s·ªë trong file
    import re
    weights_pattern = r"# Feature weights\s*FEATURE_WEIGHTS\s*=\s*\{[^}]*\}"
    updated_content = re.sub(weights_pattern, weights_str.rstrip(), content, flags=re.DOTALL)
    
    # T√¨m v√† thay th·∫ø percentile
    percentile_pattern = r"DEFAULT_PERCENTILE\s*=\s*[0-9.]*"
    updated_content = re.sub(percentile_pattern, f"DEFAULT_PERCENTILE = {new_percentile}", updated_content)
    
    # Ghi l·∫°i file
    with open(config_path, 'w', encoding='utf-8') as f:
        f.write(updated_content)
    
    print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t file c·∫•u h√¨nh t·∫°i {config_path}")
    return True

def update_query_file(query_path, new_weights):
    """C·∫≠p nh·∫≠t file truy v·∫•n Cypher t√≠nh anomaly score."""
    if not os.path.exists(query_path):
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file truy v·∫•n t·∫°i {query_path}")
        return False
    
    with open(query_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # T√¨m ph·∫ßn t√≠nh to√°n anomaly score
    import re
    
    # T·∫°o ph·∫ßn weighted sum m·ªõi
    weighted_sum = """WITH a, 
    (degScore * {degScore}) + 
    (prScore * {prScore}) + 
    (simScore * {simScore}) + 
    (btwScore * {btwScore}) + 
    (hubScore * {hubScore}) + 
    (authScore * {authScore}) + 
    (coreScore * {coreScore}) + 
    (triCount * {triCount}) + 
    (cycleCount * {cycleCount}) + 
    (tempBurst * {tempBurst}) + 
    (txVelocity * {txVelocity}) +
    (amountVolatility * {amountVolatility}) +
    (maxAmountRatio * {maxAmountRatio}) +
    (stdTimeBetweenTx * {stdTimeBetweenTx}) +
    ({normCommunitySize} * (1 - coalesce(normCommunitySize, 0))) AS score""".format(**new_weights)
    
    # T√¨m v√† thay th·∫ø ph·∫ßn t√≠nh to√°n
    weight_pattern = r"WITH a,\s*\((degScore.*\(1 - coalesce\(normCommunitySize, 0\)\)\) AS score"
    updated_content = re.sub(weight_pattern, weighted_sum, content, flags=re.DOTALL)
    
    # Ghi l·∫°i file
    with open(query_path, 'w', encoding='utf-8') as f:
        f.write(updated_content)
    
    print(f"‚úÖ ƒê√£ c·∫≠p nh·∫≠t file truy v·∫•n t·∫°i {query_path}")
    return True

def main():
    parser = argparse.ArgumentParser(description='C·∫≠p nh·∫≠t c·∫•u h√¨nh tr·ªçng s·ªë cho h·ªá th·ªëng ph√°t hi·ªán gian l·∫≠n')
    
    parser.add_argument('--config', type=str, default='detector/utils/config.py',
                       help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn file c·∫•u h√¨nh (m·∫∑c ƒë·ªãnh: detector/utils/config.py)')
    
    parser.add_argument('--query', type=str, default='detector/queries/anomaly_detection_queries.py',
                       help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn file truy v·∫•n (m·∫∑c ƒë·ªãnh: detector/queries/anomaly_detection_queries.py)')
    
    parser.add_argument('--weights', type=str, default=None,
                       help='ƒê∆∞·ªùng d·∫´n ƒë·∫øn file JSON ch·ª©a tr·ªçng s·ªë t√πy ch·ªânh')
    
    parser.add_argument('--percentile', type=float, default=0.995,
                       help='Ng∆∞·ª°ng ph√¢n v·ªã m·ªõi (m·∫∑c ƒë·ªãnh: 0.995)')
    
    parser.add_argument('--optimize-for', choices=['precision', 'recall', 'balanced'],
                       default='precision', help='T·ªëi ∆∞u h√≥a cho precision, recall ho·∫∑c c√¢n b·∫±ng (m·∫∑c ƒë·ªãnh: precision)')
    
    args = parser.parse_args()
    
    # Tr·ªçng s·ªë t·ªëi ∆∞u cho precision (gi·∫£m false positives)
    precision_weights = {
        'degScore': 0.60,
        'prScore': 0.02,
        'simScore': 0.01,
        'btwScore': 0.02,
        'hubScore': 0.08,
        'authScore': 0.01,
        'coreScore': 0.01,
        'triCount': 0.01,
        'cycleCount': 0.01,
        'tempBurst': 0.05,
        'txVelocity': 0.01,
        'amountVolatility': 0.02,
        'maxAmountRatio': 0.12,
        'stdTimeBetweenTx': 0.01,
        'normCommunitySize': 0.02
    }
    
    # Tr·ªçng s·ªë t·ªëi ∆∞u cho recall (gi·∫£m false negatives)
    recall_weights = {
        'degScore': 0.30,
        'prScore': 0.05,
        'simScore': 0.05,
        'btwScore': 0.05,
        'hubScore': 0.10,
        'authScore': 0.05,
        'coreScore': 0.05,
        'triCount': 0.05,
        'cycleCount': 0.05,
        'tempBurst': 0.08,
        'txVelocity': 0.05,
        'amountVolatility': 0.05,
        'maxAmountRatio': 0.05,
        'stdTimeBetweenTx': 0.02,
        'normCommunitySize': 0.05
    }
    
    # Tr·ªçng s·ªë c√¢n b·∫±ng (balanced)
    balanced_weights = {
        'degScore': 0.35,
        'prScore': 0.03,
        'simScore': 0.02,
        'btwScore': 0.03,
        'hubScore': 0.10,
        'authScore': 0.02,
        'coreScore': 0.02,
        'triCount': 0.02,
        'cycleCount': 0.02,
        'tempBurst': 0.10,
        'txVelocity': 0.03,
        'amountVolatility': 0.03,
        'maxAmountRatio': 0.20,
        'stdTimeBetweenTx': 0.01,
        'normCommunitySize': 0.02
    }
    
    # Ch·ªçn tr·ªçng s·ªë ph√π h·ª£p
    if args.optimize_for == 'precision':
        weights = precision_weights
        print("üéØ T·ªëi ∆∞u h√≥a cho precision (gi·∫£m false positives)")
    elif args.optimize_for == 'recall':
        weights = recall_weights
        print("üéØ T·ªëi ∆∞u h√≥a cho recall (gi·∫£m false negatives)")
    else:
        weights = balanced_weights
        print("üéØ T·ªëi ∆∞u h√≥a c√¢n b·∫±ng gi·ªØa precision v√† recall")
    
    # N·∫øu c√≥ file tr·ªçng s·ªë t√πy ch·ªânh, s·ª≠ d·ª•ng file ƒë√≥
    if args.weights:
        try:
            with open(args.weights, 'r') as f:
                custom_weights = json.load(f)
            weights = custom_weights
            print(f"‚úÖ ƒê√£ t·∫£i tr·ªçng s·ªë t√πy ch·ªânh t·ª´ {args.weights}")
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i file tr·ªçng s·ªë: {str(e)}")
            return
    
    # C·∫≠p nh·∫≠t file c·∫•u h√¨nh
    update_config_file(args.config, weights, args.percentile)
    
    # C·∫≠p nh·∫≠t file truy v·∫•n
    update_query_file(args.query, weights)
    
    print(f"""
    =========================================================
    ‚úÖ C·∫•u h√¨nh m·ªõi ƒë√£ ƒë∆∞·ª£c √°p d·ª•ng
    =========================================================
    ‚Ä¢ Ng∆∞·ª°ng ph√¢n v·ªã: {args.percentile*100:.2f}%
    ‚Ä¢ T·ªëi ∆∞u h√≥a cho: {args.optimize_for}
    ‚Ä¢ File c·∫•u h√¨nh: {args.config}
    ‚Ä¢ File truy v·∫•n: {args.query}
    
    C√°c tr·ªçng s·ªë m·ªõi:""")
    
    for feature, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):
        if weight > 0.05:
            print(f"    ‚Ä¢ {feature}: {weight:.2f} ‚≠ê")
        else:
            print(f"    ‚Ä¢ {feature}: {weight:.2f}")
    
    print("""
    =========================================================
    üí° ƒê·ªÉ √°p d·ª•ng c·∫•u h√¨nh m·ªõi, ch·∫°y:
    python unsupervised_anomaly_detection.py
    
    Ho·∫∑c ƒë·ªÉ c·∫£i thi·ªán th√™m n·ªØa, ch·∫°y:
    python precision_improvement.py --percentile {} --optimize-weights
    
    Ho·∫∑c s·ª≠ d·ª•ng b·ªô l·ªçc n√¢ng cao:
    python advanced_fraud_filter.py
    =========================================================
    """.format(args.percentile))

if __name__ == "__main__":
    main()
