from neo4j import GraphDatabase
import pandas as pd
import os
import time
import random

# ================= C·∫§U H√åNH =================
URI = "neo4j+s://fbf28b59.databases.neo4j.io"
USER = "neo4j"
PASS = "qdN9t-ZfZbr-XT_xbg1Tfji8OC8lrmFbfUxPof5haZI"
BATCH_SIZE = 2000  # Gi·∫£m batch size ƒë·ªÉ ti·∫øt ki·ªám b·ªô nh·ªõ
MAX_NODES = 200000
MAX_RELATIONSHIPS = 400000

# =============== TI·ªÜN √çCH X·ª¨ L√ù D·ªÆ LI·ªÜU ===============
def network_preserving_sampling(input_path, output_path, target_nodes=200000, target_edges=400000, target_fraud_rate=0.00129):
    """Ph∆∞∆°ng ph√°p l·∫•y m·∫´u b·∫£o to√†n c·∫•u tr√∫c m·∫°ng l∆∞·ªõi v√† t·ª∑ l·ªá gian l·∫≠n v·ªõi ki·ªÉm so√°t ch·∫∑t ch·∫Ω s·ªë l∆∞·ª£ng node"""
    print("‚öôÔ∏è ƒêang l·ªçc dataset v·ªõi ph∆∞∆°ng ph√°p b·∫£o to√†n c·∫•u tr√∫c m·∫°ng...")
    
    # ƒê·ªçc d·ªØ li·ªáu
    df = pd.read_csv(input_path)
    
    # B∆∞·ªõc 1: T·∫°o danh s√°ch c√°c t√†i kho·∫£n v√† giao d·ªãch
    all_accounts = set(df['nameOrig']).union(set(df['nameDest']))
    print(f"T·ªïng s·ªë t√†i kho·∫£n trong dataset g·ªëc: {len(all_accounts)}")
    print(f"T·ªïng s·ªë giao d·ªãch trong dataset g·ªëc: {len(df)}")
    
    # B∆∞·ªõc 2: T√≠nh s·ªë l∆∞·ª£ng giao d·ªãch gian l·∫≠n c·∫ßn l·∫•y m·∫´u
    target_fraud_txs = int(target_edges * target_fraud_rate)
    fraud_df = df[df['isFraud'] == 1]
    
    if len(fraud_df) <= target_fraud_txs:
        # N·∫øu c√≥ √≠t giao d·ªãch gian l·∫≠n h∆°n m·ª•c ti√™u, l·∫•y t·∫•t c·∫£
        fraud_sample = fraud_df
        print(f"L·∫•y t·∫•t c·∫£ {len(fraud_sample)} giao d·ªãch gian l·∫≠n")
    else:
        # Ng∆∞·ª£c l·∫°i, l·∫•y m·∫´u theo s·ªë l∆∞·ª£ng m·ª•c ti√™u
        fraud_sample = fraud_df.sample(n=target_fraud_txs, random_state=42)
        print(f"L·∫•y m·∫´u {len(fraud_sample)} giao d·ªãch gian l·∫≠n t·ª´ {len(fraud_df)}")
    
    # B∆∞·ªõc 3: X√°c ƒë·ªãnh c√°c t√†i kho·∫£n li√™n quan ƒë·∫øn gian l·∫≠n
    fraud_accounts = set(fraud_sample['nameOrig']).union(set(fraud_sample['nameDest']))
    print(f"S·ªë t√†i kho·∫£n li√™n quan ƒë·∫øn gian l·∫≠n: {len(fraud_accounts)}")
    
    # Theo d√µi s·ªë l∆∞·ª£ng node ƒë√£ ch·ªçn
    selected_accounts = set(fraud_accounts)
    
    # B∆∞·ªõc 4: L·∫•y th√™m c√°c giao d·ªãch c√≥ li√™n quan ƒë·∫øn t√†i kho·∫£n gian l·∫≠n (1-hop)
    related_query = df['nameOrig'].isin(fraud_accounts) | df['nameDest'].isin(fraud_accounts)
    related_txs = df[related_query & ~df.index.isin(fraud_sample.index)]
    print(f"S·ªë giao d·ªãch li√™n quan ƒë·∫øn t√†i kho·∫£n gian l·∫≠n: {len(related_txs)}")
    
    # B∆∞·ªõc 5: L·∫•y m·∫´u m·ªôt t·ª∑ l·ªá c√°c giao d·ªãch li√™n quan n·∫øu qu√° nhi·ªÅu
    # L·ª±a ch·ªçn m·ªôt s·ªë l∆∞·ª£ng h·ª£p l√Ω ƒë·ªÉ kh√¥ng tƒÉng s·ªë node qu√° nhi·ªÅu
    related_sample_size = min(len(related_txs), target_edges // 4)
    if len(related_txs) > related_sample_size:
        related_sample = related_txs.sample(n=related_sample_size, random_state=42)
    else:
        related_sample = related_txs
    print(f"L·∫•y {len(related_sample)} giao d·ªãch li√™n quan")
    
    # B∆∞·ªõc 6: C·∫≠p nh·∫≠t danh s√°ch t√†i kho·∫£n ƒë√£ ƒë∆∞·ª£c ch·ªçn
    for _, row in related_sample.iterrows():
        selected_accounts.add(row['nameOrig'])
        selected_accounts.add(row['nameDest'])
    print(f"S·ªë t√†i kho·∫£n ƒë√£ ch·ªçn sau khi th√™m 1-hop: {len(selected_accounts)}")
    
    # Ki·ªÉm tra xem ƒë√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n node ch∆∞a
    if len(selected_accounts) > target_nodes * 0.7:
        print(f"ƒê√£ ƒë·∫°t {len(selected_accounts)} nodes, gi·ªõi h·∫°n node sampling ƒë·ªÉ tr√°nh v∆∞·ª£t qu√° {target_nodes}")
        # K·∫øt h·ª£p c√°c giao d·ªãch ƒë√£ ch·ªçn
        filtered_df = pd.concat([fraud_sample, related_sample])
    else:
        # B∆∞·ªõc 7: T√≠nh s·ªë l∆∞·ª£ng giao d·ªãch c√≤n l·∫°i c·∫ßn l·∫•y m·∫´u
        remaining_txs = target_edges - len(fraud_sample) - len(related_sample)
        print(f"S·ªë giao d·ªãch c·∫ßn l·∫•y th√™m: {remaining_txs}")
        
        # B∆∞·ªõc 8: ∆Øu ti√™n l·∫•y c√°c giao d·ªãch c√≥ li√™n quan ƒë·∫øn m·∫°ng l∆∞·ªõi hi·ªán t·∫°i (2-hop)
        second_hop_query = (df['nameOrig'].isin(selected_accounts) | 
                           df['nameDest'].isin(selected_accounts))
        second_hop_txs = df[second_hop_query & 
                          ~df.index.isin(fraud_sample.index) & 
                          ~df.index.isin(related_sample.index)]
        
        # Ch·ªâ l·∫•y m·ªôt s·ªë l∆∞·ª£ng 2-hop giao d·ªãch ƒë·ªÉ kh√¥ng tƒÉng s·ªë node qu√° nhi·ªÅu
        second_hop_sample_size = min(len(second_hop_txs), remaining_txs // 2)
        if second_hop_txs.empty:
            second_hop_sample = pd.DataFrame()
        elif len(second_hop_txs) > second_hop_sample_size:
            second_hop_sample = second_hop_txs.sample(n=second_hop_sample_size, random_state=42)
        else:
            second_hop_sample = second_hop_txs
        print(f"L·∫•y th√™m {len(second_hop_sample)} giao d·ªãch t·ª´ 2-hop")
        
        # C·∫≠p nh·∫≠t danh s√°ch node ƒë√£ ch·ªçn
        for _, row in second_hop_sample.iterrows():
            selected_accounts.add(row['nameOrig'])
            selected_accounts.add(row['nameDest'])
        print(f"S·ªë t√†i kho·∫£n ƒë√£ ch·ªçn sau khi th√™m 2-hop: {len(selected_accounts)}")
        
        # B∆∞·ªõc 9: L·∫•y m·∫´u ng·∫´u nhi√™n t·ª´ c√°c giao d·ªãch c√≤n l·∫°i
        # Nh∆∞ng ch·ªâ ch·ªçn c√°c giao d·ªãch kh√¥ng t·∫°o th√™m qu√° nhi·ªÅu node m·ªõi
        remaining_txs = target_edges - len(fraud_sample) - len(related_sample) - len(second_hop_sample)
        
        # Ch·ªâ ch·ªçn nodes ƒë√£ bi·∫øt ƒë·ªÉ gi·ªØ gi·ªõi h·∫°n node
        if len(selected_accounts) > target_nodes * 0.9:
            print(f"ƒê√£ ƒë·∫°t {len(selected_accounts)} nodes, ch·ªâ l·∫•y giao d·ªãch gi·ªØa c√°c node ƒë√£ bi·∫øt")
            known_nodes_query = (df['nameOrig'].isin(selected_accounts) & 
                                df['nameDest'].isin(selected_accounts))
            candidate_txs = df[known_nodes_query & 
                             ~df.index.isin(fraud_sample.index) & 
                             ~df.index.isin(related_sample.index) &
                             ~df.index.isin(second_hop_sample.index)]
        else:
            # C√≥ th·ªÉ ch·∫•p nh·∫≠n m·ªôt s·ªë node m·ªõi
            candidate_txs = df[~df.index.isin(fraud_sample.index) & 
                             ~df.index.isin(related_sample.index) &
                             ~df.index.isin(second_hop_sample.index)]
        
        random_sample = pd.DataFrame()
        if remaining_txs > 0 and not candidate_txs.empty:
            random_sample = candidate_txs.sample(n=min(remaining_txs, len(candidate_txs)), random_state=42)
            print(f"L·∫•y th√™m {len(random_sample)} giao d·ªãch ng·∫´u nhi√™n")
            
            # C·∫≠p nh·∫≠t danh s√°ch node
            for _, row in random_sample.iterrows():
                selected_accounts.add(row['nameOrig'])
                selected_accounts.add(row['nameDest'])
        
        # K·∫øt h·ª£p t·∫•t c·∫£ c√°c giao d·ªãch
        filtered_df = pd.concat([fraud_sample, related_sample, second_hop_sample, random_sample])
    
    # T√≠nh t·ªâ l·ªá gian l·∫≠n sau khi l·∫•y m·∫´u
    current_fraud_rate = len(filtered_df[filtered_df['isFraud'] == 1]) / len(filtered_df)
    target_fraud_count = int(len(filtered_df) * target_fraud_rate)
    current_fraud_count = len(filtered_df[filtered_df['isFraud'] == 1])
    
    # ƒêi·ªÅu ch·ªânh t·ªâ l·ªá gian l·∫≠n n·∫øu c·∫ßn
    if current_fraud_count > target_fraud_count:
        # Qu√° nhi·ªÅu gian l·∫≠n - Th√™m giao d·ªãch b√¨nh th∆∞·ªùng
        non_fraud_df = df[df['isFraud'] == 0]
        non_fraud_df = non_fraud_df[~non_fraud_df.index.isin(filtered_df.index)]
        
        # ∆Øu ti√™n giao d·ªãch gi·ªØa c√°c node ƒë√£ bi·∫øt
        known_nodes_query = (non_fraud_df['nameOrig'].isin(selected_accounts) & 
                            non_fraud_df['nameDest'].isin(selected_accounts))
        priority_txs = non_fraud_df[known_nodes_query]
        
        if not priority_txs.empty:
            additional_count = min(len(priority_txs), int((current_fraud_count - target_fraud_count) / target_fraud_rate))
            additional_txs = priority_txs.sample(n=min(additional_count, len(priority_txs)), random_state=42)
            filtered_df = pd.concat([filtered_df, additional_txs])
            print(f"Th√™m {len(additional_txs)} giao d·ªãch b√¨nh th∆∞·ªùng ƒë·ªÉ ƒëi·ªÅu ch·ªânh t·ªâ l·ªá gian l·∫≠n")
    
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc cu·ªëi c√πng
    nodes = len(set(filtered_df['nameOrig']).union(set(filtered_df['nameDest'])))
    relationships = len(filtered_df)
    fraud_count = len(filtered_df[filtered_df['isFraud'] == 1])
    
    # N·∫øu v·∫´n v∆∞·ª£t qu√° gi·ªõi h·∫°n node, √°p d·ª•ng l·ªçc m·∫°nh
    if nodes > target_nodes:
        print(f"V·∫´n v∆∞·ª£t qu√° gi·ªõi h·∫°n node ({nodes} > {target_nodes}), √°p d·ª•ng l·ªçc nghi√™m ng·∫∑t...")
        
        # T√≠nh s·ªë l∆∞·ª£ng node c·∫ßn lo·∫°i b·ªè
        excess_ratio = nodes / target_nodes
        target_txs = int(len(filtered_df) / excess_ratio)
        
        # ∆Øu ti√™n gi·ªØ l·∫°i giao d·ªãch gian l·∫≠n
        fraud_txs = filtered_df[filtered_df['isFraud'] == 1]
        non_fraud_txs = filtered_df[filtered_df['isFraud'] == 0]
        
        # L·∫•y danh s√°ch t√†i kho·∫£n t·ª´ giao d·ªãch gian l·∫≠n
        fraud_accounts = set(fraud_txs['nameOrig']).union(set(fraud_txs['nameDest']))
        
        # T·∫°o danh s√°ch t√†i kho·∫£n ∆∞u ti√™n gi·ªØ l·∫°i
        priority_accounts = set(fraud_accounts)
        
        # T√≠nh s·ªë l∆∞·ª£ng giao d·ªãch kh√¥ng gian l·∫≠n c·∫ßn gi·ªØ l·∫°i
        target_non_fraud = max(1, min(target_txs - len(fraud_txs), len(non_fraud_txs)))
        
        # ∆Øu ti√™n gi·ªØ l·∫°i giao d·ªãch li√™n quan ƒë·∫øn t√†i kho·∫£n gian l·∫≠n
        related_query = non_fraud_txs['nameOrig'].isin(priority_accounts) | non_fraud_txs['nameDest'].isin(priority_accounts)
        related_txs = non_fraud_txs[related_query]
        
        if len(related_txs) > target_non_fraud:
            # N·∫øu c√≥ qu√° nhi·ªÅu giao d·ªãch li√™n quan, ∆∞u ti√™n c√°c giao d·ªãch c√≥ √≠t node m·ªõi nh·∫•t
            kept_non_fraud = pd.DataFrame()
            
            # T√≠nh s·ªë node m·ªõi ƒë∆∞·ª£c th√™m b·ªüi m·ªói giao d·ªãch
            txs_with_scores = []
            current_nodes = set(fraud_txs['nameOrig'].unique()) | set(fraud_txs['nameDest'].unique())
            
            for idx, row in related_txs.iterrows():
                new_nodes = 0
                if row['nameOrig'] not in current_nodes:
                    new_nodes += 1
                if row['nameDest'] not in current_nodes:
                    new_nodes += 1
                txs_with_scores.append((idx, new_nodes))
            
            # S·∫Øp x·∫øp theo s·ªë node m·ªõi (√≠t nh·∫•t tr∆∞·ªõc)
            txs_with_scores.sort(key=lambda x: x[1])
            
            # L·∫•y n giao d·ªãch ƒë·∫ßu ti√™n
            selected_indices = [x[0] for x in txs_with_scores[:target_non_fraud]]
            kept_non_fraud = related_txs.loc[selected_indices]
        else:
            kept_non_fraud = related_txs
            remaining = target_non_fraud - len(related_txs)
            if remaining > 0:
                # L·∫•y c√°c giao d·ªãch c√≤n l·∫°i, ∆∞u ti√™n c√°c giao d·ªãch v·ªõi node ƒë√£ bi·∫øt
                remaining_txs = non_fraud_txs[~related_query]
                if not remaining_txs.empty:
                    # T√≠nh ƒëi·ªÉm ∆∞u ti√™n cho m·ªói giao d·ªãch
                    current_nodes = set(fraud_txs['nameOrig'].unique()) | set(fraud_txs['nameDest'].unique()) | \
                                  set(kept_non_fraud['nameOrig'].unique()) | set(kept_non_fraud['nameDest'].unique())
                    
                    txs_with_scores = []
                    for idx, row in remaining_txs.iterrows():
                        new_nodes = 0
                        if row['nameOrig'] not in current_nodes:
                            new_nodes += 1
                        if row['nameDest'] not in current_nodes:
                            new_nodes += 1
                        txs_with_scores.append((idx, new_nodes))
                    
                    # S·∫Øp x·∫øp theo s·ªë node m·ªõi (√≠t nh·∫•t tr∆∞·ªõc)
                    txs_with_scores.sort(key=lambda x: x[1])
                    
                    # L·∫•y n giao d·ªãch ƒë·∫ßu ti√™n
                    selected_indices = [x[0] for x in txs_with_scores[:remaining]]
                    if selected_indices:
                        kept_non_fraud = pd.concat([kept_non_fraud, remaining_txs.loc[selected_indices]])
        
        # K·∫øt h·ª£p l·∫°i
        filtered_df = pd.concat([fraud_txs, kept_non_fraud])
        
        # Ki·ªÉm tra l·∫°i
        nodes = len(set(filtered_df['nameOrig']).union(set(filtered_df['nameDest'])))
        relationships = len(filtered_df)
        fraud_count = len(filtered_df[filtered_df['isFraud'] == 1])
    
    print(f"\n‚úÖ K·∫øt qu·∫£ cu·ªëi c√πng:")
    print(f"- Nodes: {nodes} (m·ª•c ti√™u: {target_nodes})")
    print(f"- Relationships: {relationships} (m·ª•c ti√™u: {target_edges})")
    print(f"- Giao d·ªãch gian l·∫≠n: {fraud_count}")
    print(f"- T·ª∑ l·ªá fraud: {fraud_count/relationships*100:.4f}% (m·ª•c ti√™u: {target_fraud_rate*100:.4f}%)")
    
    filtered_df.to_csv(output_path, index=False)
    return output_path


class FraudDetector:
    def __init__(self):
        self.driver = GraphDatabase.driver(URI, auth=(USER, PASS))
        
    def check_data(self):
        """Ki·ªÉm tra xem ƒë√£ c√≥ d·ªØ li·ªáu trong database ch∆∞a"""
        with self.driver.session() as session:
            result = session.run("MATCH (n) RETURN count(n) as count")
            return result.single()["count"] > 0
        
    def import_data(self, csv_path):
        """Import d·ªØ li·ªáu v√†o Neo4j v·ªõi ki·ªÉm tra k√≠ch th∆∞·ªõc"""
        with self.driver.session() as session:
            # Ki·ªÉm tra dataset tr∆∞·ªõc khi import
            df = pd.read_csv(csv_path)
            nodes = len(set(df['nameOrig']).union(set(df['nameDest'])))
            relationships = len(df)
            
            if nodes > MAX_NODES or relationships > MAX_RELATIONSHIPS:
                print(f"‚ö†Ô∏è C·∫¢NH B√ÅO: Dataset c√≥ th·ªÉ v∆∞·ª£t qu√° gi·ªõi h·∫°n: {nodes} nodes, {relationships} relationships")
                print("Ti·∫øn h√†nh l·ªçc th√™m d·ªØ li·ªáu...")
                
                # N·∫øu v∆∞·ª£t qu√° gi·ªõi h·∫°n, ti·∫øp t·ª•c l·ªçc
                temp_csv = "temp_filtered.csv"
                max_nodes = MAX_NODES * 0.9  # Gi·ªØ d∆∞·ªõi 90% ƒë·ªÉ an to√†n
                max_rels = MAX_RELATIONSHIPS * 0.9
                
                # L·ªçc dataset
                network_preserving_sampling(csv_path, temp_csv, 
                                          target_nodes=int(max_nodes), 
                                          target_edges=int(min(max_rels, relationships)),
                                          target_fraud_rate=len(df[df['isFraud'] == 1])/len(df))
                
                # ƒê·ªçc l·∫°i dataset ƒë√£ l·ªçc
                df = pd.read_csv(temp_csv)
                nodes = len(set(df['nameOrig']).union(set(df['nameDest'])))
                relationships = len(df)
                csv_path = temp_csv
                
                print(f"Dataset sau khi l·ªçc: {nodes} nodes, {relationships} relationships")

            # X√≥a d·ªØ li·ªáu c≈©
            session.run("MATCH (n) DETACH DELETE n")
            
            # Import theo batch
            records = []
            for row in df.itertuples():
                records.append({
                    "from_ac": row.nameOrig,
                    "to_ac": row.nameDest,
                    "amt": float(row.amount),  # ƒê·∫£m b·∫£o ki·ªÉu d·ªØ li·ªáu
                    "step": int(row.step),     # ƒê·∫£m b·∫£o ki·ªÉu d·ªØ li·ªáu
                    "is_fraud": int(row.isFraud),
                    "type": row.type
                })
                
                if len(records) >= BATCH_SIZE:
                    self._process_batch(session, records)
                    records = []
                    
            if records:
                self._process_batch(session, records)

    def _process_batch(self, session, batch):
        """X·ª≠ l√Ω t·ª´ng batch d·ªØ li·ªáu"""
        try:
            query = """
            UNWIND $batch AS tx
            MERGE (a:Account {id: tx.from_ac})
            MERGE (b:Account {id: tx.to_ac})
            MERGE (a)-[r:SENT {step: tx.step}]->(b)
            ON CREATE SET 
                r.amount = tx.amt,
                r.is_fraud = tx.is_fraud,
                r.type = tx.type
            """
            session.run(query, {"batch": batch})
            print(f"ƒê√£ import {len(batch)} giao d·ªãch")
        except Exception as e:
            print(f"L·ªói khi import batch: {e}")
    
    def analyze_fraud(self):
        """Ch·∫°y ph√¢n t√≠ch gian l·∫≠n"""
        with self.driver.session() as session:
            # T·∫°o index
            session.run("CREATE INDEX IF NOT EXISTS FOR (a:Account) ON (a.id)")
            
            # Ki·ªÉm tra GDS plugin
            try:
                session.run("CALL gds.list()")
            except Exception as e:
                print(f"L·ªói GDS plugin: {e}")
                print("H√£y ƒë·∫£m b·∫£o Graph Data Science plugin ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t")
                return
                
            # T·∫°o projected graph
            try:
                print("üîç ƒêang t·∫°o projected graph...")
                session.run("""
                    CALL gds.graph.project(
                        'fraud_graph',
                        'Account',
                        'SENT',
                        {
                            relationshipProperties: {
                                amount: {property: 'amount', defaultValue: 0.0},
                                is_fraud: {property: 'is_fraud', defaultValue: 0}
                            }
                        }
                    )
                """)
            except Exception as e:
                print(f"L·ªói khi t·∫°o projected graph: {e}")
                return
            
            # Ch·∫°y thu·∫≠t to√°n ƒë·ªì th·ªã
            try:
                print("üîç ƒêang ch·∫°y PageRank...")
                session.run("""
                    CALL gds.pageRank.write({
                        graphName: 'fraud_graph',
                        writeProperty: 'fraud_score',
                        maxIterations: 20
                    })
                """)
            except Exception as e:
                print(f"L·ªói khi ch·∫°y PageRank: {e}")
                
            try:
                print("üîç ƒêang ph√°t hi·ªán c·ªông ƒë·ªìng...")
                session.run("""
                    CALL gds.louvain.write({
                        graphName: 'fraud_graph',
                        writeProperty: 'community'
                    })
                """)
            except Exception as e:
                print(f"L·ªói khi ph√°t hi·ªán c·ªông ƒë·ªìng: {e}")
            
            # D·ªçn d·∫πp projected graph
            try:
                session.run("CALL gds.graph.drop('fraud_graph')")
            except:
                pass
                
            # Truy v·∫•n k·∫øt qu·∫£
            try:
                result = session.run("""
                    MATCH (a:Account)
                    WHERE a.fraud_score > 0.5
                    RETURN a.id AS account, 
                           a.fraud_score AS score,
                           a.community AS community,
                           [(a)-[r:SENT]->() WHERE r.is_fraud = 1 | r.amount] AS fraud_transactions
                    ORDER BY score DESC
                    LIMIT 20
                """)
                
                print("\n TOP T√ÄI KHO·∫¢N ƒê√ÅNG NG·ªú:")
                for record in result:
                    print(f"‚îÇ {record['account']} ‚îÇ Score: {record['score']:.2f} ‚îÇ Community: {record['community']} ‚îÇ")
                    print(f"‚îî‚Üí {len(record['fraud_transactions'])} giao d·ªãch gian l·∫≠n")  # S·ª≠a l·ªói string format
            except Exception as e:
                print(f"L·ªói khi truy v·∫•n k·∫øt qu·∫£: {e}")

    def has_data(self):
        """Ki·ªÉm tra xem ƒë√£ c√≥ d·ªØ li·ªáu trong database ch∆∞a"""
        with self.driver.session() as session:
            result = session.run("MATCH (n) RETURN count(n) as count")
            return result.single()["count"] > 0
    

if __name__ == "__main__":
    try:
        # B∆∞·ªõc 1: L·ªçc dataset
        input_csv = "transactions.csv"
        filtered_csv = "filtered_paysim.csv"
        
        if not os.path.exists(filtered_csv):
            if not os.path.exists(input_csv):
                print(f"Kh√¥ng t√¨m th·∫•y file {input_csv}!")
                exit(1)
            network_preserving_sampling(input_csv, filtered_csv, 
                                    target_nodes=180000,  # Gi·∫£m xu·ªëng ƒë·ªÉ ƒë·∫£m b·∫£o kh√¥ng v∆∞·ª£t qu√° 200k
                                    target_edges=193500,  # Gi·ªØ nguy√™n s·ªë giao d·ªãch nh∆∞ ƒë√£ y√™u c·∫ßu
                                    target_fraud_rate=0.00129)
            
        # B∆∞·ªõc 2: Kh·ªüi t·∫°o h·ªá th·ªëng
        detector = FraudDetector()
        
        # B∆∞·ªõc 3: Import d·ªØ li·ªáu n·∫øu c·∫ßn
        if detector.check_data():
            print("D·ªØ li·ªáu ƒë√£ t·ªìn t·∫°i trong database, b·ªè qua b∆∞·ªõc import...")
        else:
            print("ƒêang import d·ªØ li·ªáu v√†o Neo4j...")
            start = time.time()
            detector.import_data(filtered_csv)
            print(f"Th·ªùi gian import: {time.time() - start:.2f}s")
        
        # B∆∞·ªõc 4: Ph√¢n t√≠ch
        detector.analyze_fraud()
        
    except Exception as e:
        print(f"L·ªói: {e}")
    finally:
        if 'detector' in locals():
            detector.driver.close()